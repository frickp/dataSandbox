{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "My goal is to learn how to scrape data using python.\n",
    "\n",
    "This is my first time scraping from the web. I found this documentation *extremely* helpful http://www.gregreda.com/2015/02/15/web-scraping-finding-the-api/. Here, I'm pulling in the shot log for Andrew Wiggins, the NBA Rookie of the Year last year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the info needed, you can navigate to the website that gives the data you want. Using Chrome developer tools, you can navigate to find the API and see the structure of the request by previewing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shotsUrl = 'http://stats.nba.com/stats/playerdashptshotlog?DateFrom=&DateTo=&' + \\\n",
    "    'GameSegment=&LastNGames=0&LeagueID=00&Location=&Month=0&' + \\\n",
    "    'OpponentTeamID=0&Outcome=&Period=0&PlayerID=203952&Season=2014-15' + \\\n",
    "    '&SeasonSegment=&SeasonType=Regular+Season&TeamID=0&VsConference=&VsDivision='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use requests to get the data back in json format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(shotsUrl)\n",
    "response.raise_for_status()\n",
    "shots = response.json()['resultSets'][0]['rowSet']\n",
    "colNames = response.json()['resultSets'][0]['headers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having all the data in memory, arrange it and put it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfShots = pd.DataFrame(shots,columns=colNames)\n",
    "dfShots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of data here. Let's just start with a quick analysis of how much time was on the shot clock when Wiggins shot the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allShots = dfShots[np.invert(np.isnan(dfShots.SHOT_CLOCK))]\n",
    "fig = plt.figure(figsize=(5,4), dpi=1600)\n",
    "ax = fig.add_subplot(111)\n",
    "allShots['SHOT_CLOCK'].hist(normed = True,bins=20,alpha=0.4,linewidth=0.4)\n",
    "ax.set_xlabel('Shot clock (s)',fontsize=16,fontweight='bold')\n",
    "ax.set_ylabel('Density',fontsize=16,fontweight='bold')\n",
    "fig.suptitle('Andrew Wiggins',fontsize=20,fontweight='bold')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue to dig into the data. Next let's just compare the same data divided into made shots and missed shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4), dpi=1600)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "madeShots = dfShots[(dfShots.SHOT_RESULT=='made') & (np.invert(np.isnan(dfShots.SHOT_CLOCK)))]\n",
    "#madeShots = allShots[allShots.SHOT_RESULT=='made']\n",
    "missedShots = dfShots[(dfShots.SHOT_RESULT=='missed') & (np.invert(np.isnan(dfShots.SHOT_CLOCK)))]\n",
    "\n",
    "madeShots['SHOT_CLOCK'].hist(normed = True,bins=20,alpha=0.3,linewidth=0.4,label='made')\n",
    "missedShots['SHOT_CLOCK'].hist(normed = True,bins=20,alpha=0.3,linewidth=0.4,label='missed')\n",
    "plt.legend(loc='upper right',framealpha=0)\n",
    "\n",
    "ax.set_xlabel('Shot clock (s)',fontsize=16,fontweight='bold')\n",
    "ax.set_ylabel('Density',fontsize=16,fontweight='bold')\n",
    "fig.suptitle('Andrew Wiggins',fontsize=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the missed shots and made shots pretty much overlap. A couple of interesting points. The made shots density is relatively higher with more time left on the shot clock. This is probably due to quick put-back shots. At low time left, the missed is slightly higher, suggesting possible forced low-quality shots as the shot clock is expiring.\n",
    "\n",
    "There's obviously a lot more room for analysis here. But I'm happy that after fumbling through this I have a much better grasp on scraping web data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nike bootstraps\n",
    "A quick diversion. We have these two distributions, and they look different by eye, but can we say with confidence that the sample means are not the same? To translate that to statistics mumbo jumbo, can we reject the null hypothesis that these two distributions have equal sample means?\n",
    "\n",
    "If the data were nice pretty Gaussians, then a t-test would be perfect. I'm not sure what distribution describes the time remaining on the shot clock, so we'll instead take a _non-parametric approach_, that is, to not assume knowledge of the underlying distributions.\n",
    "\n",
    "So... let's use bootstrapping to estimate the error of the estimates of the means for the two distributions. This will tell us if we can distinguish these distributions with confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write a function to resample the sample data. \n",
    "\n",
    "__Wait, you are seriously going to use only your data to make up more theoretical data and use this to draw conclusions about the real-world error of the original data?__  \n",
    "\n",
    "Okay, so this hits a nerve. The experimentalist in me has had the luxury of resampling from the population by just doing another experiment. This is obiously the ideal case. So I've always kind of kept a healthy skepticism every time I thought about bootstrap resampling.\n",
    "\n",
    "Apparently it is called  bootstrapping precisely because it is physically impossible to pull yourself up off the ground by pulling your own bootstraps (wiki ref). This happens to work in statistics though. Think of it this way, as your sample increases in size, it will more closely approximate the underlying distribution of the data. \n",
    "\n",
    "___Bootstrapping relies upon the assumption that your sample closely resembles the unobserved/theoretical population distribution___. Therefore sampling from your sample is equivalent to sampling from the the population. This makes sense for larger sample sizes, but I would stay cautious using bootstrapping with small samples, because the sample may not resemble the total population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, to the bootstraps. Here's a function to return the 95% confidence interval for the estimate of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCI(dist,n=1000):\n",
    "    bootMean = []\n",
    "    for i in range(n):\n",
    "        newDist = resample(dist)\n",
    "        bootMean.append(newDist.mean())\n",
    "    bootMean = sorted(bootMean)\n",
    "    madeCI = {'lower': bootMean[int(n*0.025)], 'upper': bootMean[int(n*0.975)], 'mean': bootMean[int(n*0.5)]}\n",
    "    return madeCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, resample 1,000 times to calculate the 95% CI of the mean shot clock time remaining for both the made and missed shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "made = getCI(madeShots['SHOT_CLOCK'],1000)\n",
    "missed = getCI(missedShots['SHOT_CLOCK'],1000)\n",
    "\n",
    "madeUp = abs(made['upper'] - made['mean'])\n",
    "madeLow = abs(made['lower'] - made['mean'])\n",
    "print \"Made shots abs. error intervals:\\n\" + str(madeLow) +', ' + str(madeUp) + '\\n'\n",
    "missedUp = abs(missed['upper'] - missed['mean'])\n",
    "missedLow = abs(missed['lower'] - missed['mean'])\n",
    "print \"Missed shots abs. error intervals:\\n\" + str(missedLow) + ', ' + str(missedUp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6), dpi=1600)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "madeShots = dfShots[(dfShots.SHOT_RESULT=='made') & (np.invert(np.isnan(dfShots.SHOT_CLOCK)))]\n",
    "#madeShots = allShots[allShots.SHOT_RESULT=='made']\n",
    "missedShots = dfShots[(dfShots.SHOT_RESULT=='missed') & (np.invert(np.isnan(dfShots.SHOT_CLOCK)))]\n",
    "\n",
    "madeShots['SHOT_CLOCK'].hist(normed = True,bins=20,alpha=0.3,linewidth=0.4,label='made')\n",
    "missedShots['SHOT_CLOCK'].hist(normed = True,bins=20,alpha=0.3,linewidth=0.4,label='missed')\n",
    "plt.legend(loc='upper right',framealpha=0)\n",
    "\n",
    "ax.set_xlabel('Shot clock (s)',fontsize=16,fontweight='bold')\n",
    "ax.set_ylabel('Density',fontsize=16,fontweight='bold')\n",
    "fig.suptitle('Andrew Wiggins',fontsize=20,fontweight='bold')\n",
    "\n",
    "plt.errorbar(x=[made['mean']],y=[0.05],xerr=[[madeLow],[madeUp]],linewidth=3,capthick=3,ecolor='b')\n",
    "plt.errorbar(x=[missed['mean']],y=[0.05],xerr=[[missedLow],[missedUp]],linewidth=3,capthick=3,ecolor='g')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cMin,cSec = allShots['GAME_CLOCK'].str.split(':').str.get(0),allShots['GAME_CLOCK'].str.split(':').str.get(1)\n",
    "cMin,cSec = allShots.loc[:,'GAME_CLOCK'].str.split(':').str.get(0),allShots['GAME_CLOCK'].str.split(':').str.get(1)\n",
    "\n",
    "allShots.loc[:,'secGameClock'] = cMin.astype('int') * 60 + cSec.astype('int')\n",
    "#allShots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dummify variables\n",
    "\n",
    "pd.get_dummies(allShots[['W','LOCATION','FGM']])\n",
    "allShots.loc[:,'gameWon'] = pd.get_dummies(allShots['W'])['W']\n",
    "allShots.loc[:,'homeGame'] = pd.get_dummies(allShots['LOCATION'])['H']\n",
    "allShots.loc[:,'is3Pointer'] = pd.get_dummies(allShots['PTS_TYPE'])[3]\n",
    "q = pd.get_dummies(allShots['PERIOD'])[[2,3,4,5]]\n",
    "allShots = pd.concat([allShots,q],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropThese = ['GAME_ID','MATCHUP','CLOSEST_DEFENDER','CLOSEST_DEFENDER_PLAYER_ID','GAME_CLOCK','SHOT_RESULT','LOCATION','W','PERIOD','PTS_TYPE','PTS']\n",
    "[ allShots.drop(i, axis=1, inplace=True) for i in dropThese ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainShots = allShots[1::2] #Odd rows\n",
    "testShots = allShots[::2] #Even rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scAllShots = pd.DataFrame(sk.preprocessing.scale(allShots),index=allShots.index,columns=allShots.columns)\n",
    "scTrainShots = scAllShots[1::2] \n",
    "scTestShots = scAllShots[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I'm developing this one to read in data and make train/test based on an index\n",
    "\n",
    "def myLearning(myData,myMod,trainSet,testSet,scaleIt=False): #Make this a function of train/test set, scale, algorithm\n",
    "    if scaleIt == True,\n",
    "    print 'Algorithm used:\\n' + myMod + '\\n'\n",
    "    myEst = eval(myMod)\n",
    "    myEst.fit(\n",
    "        eval(trainSet)[predCol],\n",
    "        eval(trainSet)['FGM']\n",
    "    )\n",
    "    matches = np.count_nonzero(myEst.predict(eval(testSet)[predCol]) == eval(testSet)['FGM'])\n",
    "    testLen = eval(testSet).shape[0]\n",
    "    print \"Correctly classified:\\n\" + str(round(float(matches) / testLen * 100,2)) + '%'\n",
    "\n",
    "\n",
    "myLearn(myMod='linear_model.LogisticRegression()',trainSet='trainShots',testSet='testShots') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This one is working\n",
    "\n",
    "# Test function to output prediction value based on different models, training data, test data, and if\n",
    "# results should be scaled.\n",
    "\n",
    "def myLearning(myMod,trainSet,testSet): #Make this a function of train/test set, scale, algorithm\n",
    "    print 'Algorithm used:\\n' + myMod + '\\n'\n",
    "    myEst = eval(myMod)\n",
    "    myEst.fit(\n",
    "        eval(trainSet)[predCol],\n",
    "        eval(trainSet)['FGM']\n",
    "    )\n",
    "    matches = np.count_nonzero(myEst.predict(eval(testSet)[predCol]) == eval(testSet)['FGM'])\n",
    "    testLen = eval(testSet).shape[0]\n",
    "    print \"Correctly classified:\\n\" + str(round(float(matches) / testLen * 100,2)) + '%'\n",
    "\n",
    "\n",
    "        \n",
    "    #    np.count_nonzero(results['svmTF'])/float(len(results))*100\n",
    "    # if scl == T, scale data\n",
    "    # if == truth value, count\n",
    "\n",
    "    # \n",
    "\n",
    "myLearn(myMod='linear_model.LogisticRegression()',trainSet='trainShots',testSet='testShots') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predCol = [col for col in allShots.columns if col != 'FGM']\n",
    "print predCol\n",
    "\n",
    "estLog = linear_model.LogisticRegression()\n",
    "estLog.fit(trainShots[predCol],trainShots['FGM'])\n",
    "estSVM = svm.SVC()\n",
    "estSVM.fit(trainShots[predCol],trainShots['FGM'])\n",
    "estscSVM = svm.SVC()\n",
    "estscSVM.fit(scTrainShots[predCol],scTrainShots['FGM'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predLog'] = estLog.predict(testShots[predCol])\n",
    "results['predSVM'] = estSVM.predict(testShots[predCol])\n",
    "\n",
    "results['scPredSVM'] = estscSVM.predict(scTestShots[predCol])\n",
    "#NuSVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['actual'] = np.array(testShots['FGM'])\n",
    "results['scActual'] = np.array(scTestShots['FGM'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['logTF'] = results['predLog'] == results['actual']\n",
    "results['svmTF'] = results['predSVM'] == results['actual']\n",
    "\n",
    "results['scSvmTF'] = results['scPredSVM'] == results['scActual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.count_nonzero(results['logTF'])/float(len(results))*100\n",
    "print np.count_nonzero(results['svmTF'])/float(len(results))*100\n",
    "\n",
    "print np.count_nonzero(results['scSvmTF'])/float(len(results))*100\n",
    "\n",
    "#trainShots[predCol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estLog = linear_model.LogisticRegression()\n",
    "estLog.fit(trainShots[predCol],trainShots['FGM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predCol = [col for col in allShots.columns if col != 'FGM']\n",
    "allShots = allShots.reset_index(drop=True)\n",
    "\n",
    "loo = cross_validation.LeaveOneOut(len(allShots))\n",
    "estLog = linear_model.LogisticRegression()\n",
    "svmCorrect, logCorrect = 0, 0\n",
    "for trainIdx, testIdx in loo:\n",
    "    trainShots = allShots.loc[trainIdx]\n",
    "    estLog = linear_model.LogisticRegression()\n",
    "    estLog.fit(trainShots[predCol],trainShots['FGM'])\n",
    "    estSVM = svm.SVC()\n",
    "    estSVM.fit(trainShots[predCol],trainShots['FGM'])\n",
    "    testShots = allShots.loc[testIdx]\n",
    "    if int(estLog.predict(testShots[predCol])) == int(testShots['FGM']):\n",
    "        logCorrect += 1\n",
    "    if int(estSVM.predict(testShots[predCol])) == int(testShots['FGM']):\n",
    "        svmCorrect += 1\n",
    "logClass = round(logCorrect/float(len(allShots))*100,2)\n",
    "svmClass = round(svmCorrect/float(len(allShots))*100,2)\n",
    "print \"Logistic regression prediction accuracy: \" + str(logClass) + \" \\n\"\n",
    "print \"Support vector machine prediction accuracy: \" + str(svmClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figuring out scaling. \n",
    "\n",
    "p = pd.DataFrame({'a': 20+50*np.random.randn(10),'b':np.random.randn(10)})\n",
    "print np.std(sk.preprocessing.scale(p)[:,0]), np.std(sk.preprocessing.scale(p)[:,1])\n",
    "print np.mean(sk.preprocessing.scale(p)[:,0]), np.mean(sk.preprocessing.scale(p)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
